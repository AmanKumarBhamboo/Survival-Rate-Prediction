{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf95f051-a20b-4328-ba6d-9fcccd17baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2770c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2569d4d1-1246-47c0-bcf9-3709da48ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0157fb8e-71cb-41fa-9b52-0c2361b09b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('df_dropped_values.csv')\n",
    "df2 = pd.read_csv('df_imputated_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ad49850-811b-492d-a1c9-5081eb248a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('float64'), dtype('int64'), dtype('bool')], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c70320ac-7346-4b76-8245-6572c8819ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('float64'), dtype('int64'), dtype('bool')], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dtypes.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cecf77",
   "metadata": {},
   "source": [
    "There are boolean values due to one-hot encoding so first we will treat them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d068bd2-70c3-4767-95aa-ddb70653b1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1.select_dtypes(bool).columns] = df1.select_dtypes(bool).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8bb6eff-ee76-4f3c-a47b-485b58fdb67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2.select_dtypes(bool).columns] = df2.select_dtypes(bool).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251e1f11",
   "metadata": {},
   "source": [
    "Our dataset is very big so I will just use it's sample to do our model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "404ab279",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_reduced = df1.sample(n=25000, random_state=42)\n",
    "df2_reduced = df2.sample(n=25000, random_state=42)\n",
    "\n",
    "X1 = df1_reduced.drop(columns=['hospital_death'])\n",
    "y1 = df1_reduced['hospital_death']\n",
    "\n",
    "X2 = df2_reduced.drop(columns=['hospital_death'])\n",
    "y2 = df2_reduced['hospital_death']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5990efeb",
   "metadata": {},
   "source": [
    "## I will apply the scaling and normalization in these cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cd2756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "import numpy as np\n",
    "\n",
    "# Apply robust scaling (handles outliers better than StandardScaler)\n",
    "scaler = RobustScaler()\n",
    "X1 = scaler.fit_transform(X1)\n",
    "X2 = scaler.transform(X2)\n",
    "\n",
    "# Clip extreme values to avoid overflow\n",
    "X1 = np.clip(X1, -10, 10)\n",
    "X2 = np.clip(X2, -10, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "275ec2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "\n",
    "normalizer = Normalizer()  \n",
    "\n",
    "X1 = normalizer.fit_transform(X1)\n",
    "X2 = normalizer.transform(X2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b591c3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed57f831",
   "metadata": {},
   "source": [
    "### Logistic Regression Model Overview\n",
    "\n",
    "Logistic Regression is a supervised classification algorithm used to predict the probability of a binary outcome. It models the relationship between input features and the log-odds of the target class using a linear combination of the features. The model estimates coefficients (weights) for each feature and an intercept term.\n",
    "\n",
    "Key aspects include:\n",
    "\n",
    "* **Solver:** Optimization algorithm used to find the best-fitting coefficients (e.g., `liblinear`, `saga`). Choice depends on dataset size and penalty type.\n",
    "* **Penalty (Regularization):** Controls model complexity to prevent overfitting. Common penalties include L2 (Ridge) regularization.\n",
    "* **Regularization strength (`C`):** Inverse of regularization strength. Smaller values specify stronger regularization.\n",
    "* **Max Iterations (`max_iter`):** Number of optimization steps allowed for convergence.\n",
    "* **Model Outputs:**\n",
    "\n",
    "  * Coefficients and intercept define the decision boundary.\n",
    "  * Predicted probabilities for class membership.\n",
    "  * Classification accuracy on training and test data measures performance.\n",
    "\n",
    "Logistic Regression is effective for binary classification tasks, especially when the relationship between features and output is approximately linear in the log-odds space.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbd2a6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coef finite? True intercept finite? True\n",
      "Train acc: 0.91812\n",
      "Test  acc: 0.91952\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(\n",
    "    solver=\"liblinear\",   \n",
    "    penalty=\"l2\",\n",
    "    C=0.05,               \n",
    "    max_iter=10000,\n",
    "    tol=1e-3\n",
    ")\n",
    "clf.fit(X1, y1)\n",
    "\n",
    "print(\"coef finite?\", np.isfinite(clf.coef_).all(), \"intercept finite?\", np.isfinite(clf.intercept_).all())\n",
    "print(\"Train acc:\", clf.score(X1, y1))\n",
    "print(\"Test  acc:\",  clf.score(X2, y2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98139c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9209\n",
      "Test accuracy: 0.9294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model2 = LogisticRegression(solver='saga', max_iter=500, C=1.0, penalty='l2')\n",
    "model2.fit(X2_train, y2_train)\n",
    "# Accuracy on training data\n",
    "train_accuracy = model2.score(X2_train, y2_train)\n",
    "print(\"Train accuracy:\", train_accuracy)\n",
    "\n",
    "# Accuracy on test data (if you have X2_test, y2_test)\n",
    "test_accuracy = model2.score(X2_test, y2_test)\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
